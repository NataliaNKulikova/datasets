{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9vkEvFABbN"
      },
      "source": [
        "# Как обучить модель c ограничивающими рамками ориентированную на yolov8\n",
        "\n",
        "---\n",
        "\n",
        "[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/yolov8-keypoint-detection-custom-train)\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)\n",
        "\n",
        "Ultralytics YOLOv8 одна из последних  версий модели обнаружения объектов и сегментации изображений YOLO (вы смотрите только один раз), разработанной  Ultralytics.\n",
        "\n",
        "В этом руководстве будет рассказано, как обучить модель обнаружения с ограничивающими рамками, ориентированную на YOLOv8.\n",
        "\n",
        " [полезный материал, сопровождающий данный ноутбук по YOLOv8](https://blog.roboflow.com/train-yolov8-obb-model/).\n",
        "\n",
        "## Используйте графическое ускорение\n",
        "\n",
        "Если вы используете этот ноутбук в Google Colab, перейдите в \"Редактировать\" -> \"Настройки ноутбука\" -> \"Аппаратный ускоритель\", установите значение \"Графический процессор\" и нажмите \"Сохранить\". Это гарантирует, что в вашем ноутбуке используется графический процессор, что значительно ускорит обучение модели.\n",
        "\n",
        "\n",
        "## Шаги в этом мануале\n",
        "\n",
        "В этом руководстве мы рассмотрим:\n",
        "\n",
        "- Проверку наличия графического процессора в нашей среде Colab\n",
        "- Установку YOLOv8\n",
        "- Подготовку набора данных\n",
        "- Обучаем OBB-модель YOLOv8\n",
        "- Выполняем логический вывод на основе нашей модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "## Прежде чем вы начнете\n",
        "\n",
        "Давайте убедимся, что у нас есть доступ к графическому процессору. Для этого мы можем использовать команду \"nvidia-smi\". В случае возникновения каких-либо проблем перейдите в \"Правка\" -> \"Настройки ноутбука\" -> \"Аппаратный ускоритель\", установите значение \"Графический процессор` и нажмите `Сохранить`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "942670aa-c1b3-4cb1-8a4b-92ea44e72055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 29 12:45:37 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "bdeda50c-bb1b-45bf-d6c0-c6abbdac286b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Установка YOLOv8\n",
        "\n",
        "Для установки YOL0v8 выполняем:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdSMcABDNKW-"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics -q\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LXblltB36Qq"
      },
      "source": [
        "импортируем YOLOv8 в наш Notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2Xtaekw3271"
      },
      "source": [
        "## Roboflow Universe\n",
        "\n",
        "Ознакомьтесь с Roboflow Universe, хранилищем наборов данных компьютерного зрения с открытым исходным кодом. Вы можете экспортировать любой набор данных, помеченный, например, как сегментация, как набор данных с ориентированными на YOLOv8 ограничивающими рамками для использования при обучении модели с ориентированными на YOLOv8 ограничивающими рамками.\n",
        "\n",
        "\n",
        "[![Roboflow Universe](https://media.roboflow.com/notebooks/template/uni-banner-frame.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672878480290)](https://universe.roboflow.com/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JHICVjZbVKn"
      },
      "source": [
        "## Подготовка пользовательского набора данных\n",
        "\n",
        "Создание пользовательского набора данных может быть трудоемким процессом. Сбор изображений, их маркировка и экспорт в нужном формате могут занять десятки или даже сотни часов. К счастью, Roboflow делает этот процесс максимально простым и быстрым. Давайте мы покажем вам, как это сделать!\n",
        "\n",
        "### Шаг 1: Создание проекта\n",
        "\n",
        "Перед началом работы вам необходимо создать Roboflow [аккаунт](https://app.roboflow.com/login). Как только вы это сделаете, вы сможете создать новый проект в Roboflow [dashboard](https://app.roboflow.com/). Выберете \"Object Detection\" в качестве типа проекта.\n",
        "\n",
        "<img src=\"https://media.roboflow.com/obb-tutorial/create.png\" alt=\"Object detection selected on the Roboflow Create Project pop up\" height=\"300\" />\n",
        "\n",
        "### Шаг 2: Загрузка изображений\n",
        "\n",
        "Затем добавьте данные в ваш только что созданный проект. Вы можете сделать это через API или через [веб-интерфейс](https://docs.roboflow.com/adding-data/object-detection).\n",
        "\n",
        "Если вы перетащите каталог с набором данных в поддерживаемом формате, панель управления Roboflow автоматически считает изображения и аннотации вместе.\n",
        "\n",
        "<img src=\"https://media.roboflow.com/obb-tutorial/upload.png\" alt=\"Uploading images to Roboflow\" height=\"300\" />\n",
        "\n",
        "### Шаг 3: Разметка\n",
        "\n",
        "Если у вас есть только изображения, вы можете пометить их ориентированными ограничивающими рамками в [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "**Чтобы пометить ограничивающую рамку, воспользуйтесь нашим инструментом для создания полигональных аннотаций.**\n",
        "\n",
        "Вы также можете взять существующий набор данных сегментации из своей рабочей области или Roboflow Universe и экспортировать его в формате OBB.\n",
        "\n",
        "\n",
        "<img src=\"https://media.roboflow.com/obb-tutorial/annotate.png\" alt=\"Annotate an image\" height=\"300\" />\n",
        "\n",
        "### шагp 4: Генерирование новой версии датасета\n",
        "\n",
        "Теперь, когда мы добавили наши изображения и аннотации, мы можем сгенерировать версию набора данных. При создании версии вы можете выбрать предварительную обработку и дополнения. Этот шаг совершенно необязателен, однако он может позволить вам значительно повысить надежность вашей модели.\n",
        "\n",
        "<img src=\"https://media.roboflow.com/keypoint/version.png\" alt=\"Generate a dataset version\" height=\"300\" />\n",
        "\n",
        "### Шаг 5: Экспорт набора данных\n",
        "\n",
        "Как только версия набора данных будет сгенерирована, мы сможем загрузить ее для использования в обучении модели.\n",
        "\n",
        "![Сгенерировать версию набора данных](https://media.roboflow.com/keypoint/export.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSd93ZJzZZKt"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "!pip install roboflow --quiet\n",
        "\n",
        "import roboflow\n",
        "\n",
        "roboflow.login()\n",
        "\n",
        "rf = roboflow.Roboflow()\n",
        "\n",
        "project = rf.workspace(\"brad-dwyer\").project(\"aerial-solar-panels\")\n",
        "dataset = project.version(6).download(\"yolov8-obb\")\n",
        "\n",
        "import yaml\n",
        "\n",
        "with open(f'{dataset.location}/data.yaml', 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "data['path'] = dataset.location\n",
        "\n",
        "with open(f'{dataset.location}/data.yaml', 'w') as file:\n",
        "    yaml.dump(data, file, sort_keys=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Обучите модель обнаружения OBB-объектов YOLOv8\n",
        "\n",
        "Загрузив наш набор данных, мы теперь можем обучить модель обнаружения OBB-объектов YOLOv8. Запустите приведенный ниже фрагмент кода, чтобы начать обучение вашей модели.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2YkphuiaE7_"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-obb.pt')\n",
        "\n",
        "results = model.train(data=f\"{dataset.location}/data.yaml\", epochs=100, imgsz=640)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG7cc0zc41sB"
      },
      "source": [
        "Ваша модель будет тренироваться в течение 100 эпох (их количество можно изменить, если это необходимо). После тренировки вы можете запустить тестирование вашей модели, используя изображение из вашего тестового набора."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18EW7RaZ51Hv"
      },
      "source": [
        "## Протестируйте модель обнаружения объектов OBB\n",
        "\n",
        "Давайте протестируем нашу модель обнаружения объектов OBB на изображении:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIy9g1k45z9e"
      },
      "outputs": [],
      "source": [
        "model = YOLO('runs/obb/train/weights/best.pt')\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "random_file = random.choice(os.listdir(f\"{dataset.location}/test/images\"))\n",
        "file_name = os.path.join(f\"{dataset.location}/test/images\", random_file)\n",
        "\n",
        "results = model(file_name)\n",
        "\n",
        "print(results[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxsVRrkb9pZL"
      },
      "source": [
        "Мы можем визуализировать наши предсказания в виде ограничивающего прямоугольника, используя следующий код:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAG1S96m9owT"
      },
      "outputs": [],
      "source": [
        "# !pip install supervision -q\n",
        "\n",
        "import supervision as sv\n",
        "import cv2\n",
        "\n",
        "detections = sv.Detections.from_ultralytics(results[0])\n",
        "\n",
        "oriented_box_annotator = sv.OrientedBoxAnnotator()\n",
        "annotated_frame = oriented_box_annotator.annotate(\n",
        "    scene=cv2.imread(file_name),\n",
        "    detections=detections\n",
        ")\n",
        "\n",
        "sv.plot_image(image=annotated_frame, size=(16, 16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEk6BN4P70QP"
      },
      "source": [
        "Наша модель успешно определила расположение солнечных панелей на изображении. Все солнечные панели имеют ориентированную ограничивающую рамку, которая плотно прилегает к панели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovQgOj_xSNDg"
      },
      "source": [
        "## 🏆 Поздравляем\n",
        "\n",
        "### Обучающие ресурсы\n",
        "\n",
        "Компания Roboflow подготовила множество ресурсов, которые могут заинтересовать вас по мере углубления ваших знаний в области компьютерного зрения:\n",
        "\n",
        "- [Блокноты Roboflow](https://github.com/roboflow/notebooks): Хранилище из более чем 20 блокнотов, в которых рассказывается о том, как обучать пользовательские модели с использованием различных типов моделей, от YOLOv7 до SegFormer.\n",
        "- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Наша библиотека видеороликов с подробным описанием последних достижений в области компьютерного зрения, подробными руководствами, прилагающимися к нашим записным книжкам, и многим другим.\n",
        "- [Обсуждение Roboflow](https://discuss.roboflow.com/): У вас есть вопрос о том, как что-то сделать в Roboflow? Задайте свой вопрос на нашем дискуссионном форуме.\n",
        "- [Модели Roboflow](https://roboflow.com): Узнайте о современных моделях и их производительности. Найдите ссылки и учебные пособия, которые помогут вам в изучении.\n",
        "\n",
        "### Преобразование форматов данных\n",
        "\n",
        "Roboflow предоставляет бесплатные утилиты для преобразования данных между десятками популярных форматов компьютерного зрения. Ознакомьтесь с [Roboflow Formats](https://roboflow.com/formats), чтобы ознакомиться с руководствами по преобразованию данных из одного формата в другой за несколько кликов.\n",
        "\n",
        "### Подключите компьютерное зрение к логике вашего проекта\n",
        "\n",
        "[Шаблоны Roboflow](https://roboflow.com/templates) - это общедоступная галерея фрагментов кода, которые вы можете использовать для подключения компьютерного зрения к логике вашего проекта. Фрагменты кода варьируются от отправки электронных писем после логического вывода до измерения расстояния до объекта между обнаруженными объектами."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание на лабораторную работу\n",
        "## Часть 1 Детекция объектов на изображениях\n",
        "- Ознакомиться с возможностью детекции объектов с помощью YOLOv8 (по желанию можно использовать любую другую версию YOLO старше 8й версии)\n",
        "- На сайте Roboflow подобрать датасет, который подходит для детекции объектов (можно с любого другого ресурса взять аннотированный датасет, либо создать самостоятельно)\n",
        "- обучите и протестируйте модель на выбранном датасете, визуализируйте выходные данные, подтвердите, что модель работает\n",
        "- оформите отчет (в отчете необходимо привести краткий обзор версий yolov8 и выше, основные понятия и опрделения, характеристику своего датасета и параметры подключения, результаты работы)\n",
        "- итоговый ноутбук с своим датасетом и результатами, а также отчет загрузите в openedu\n",
        "\n",
        "## Часть 2 Детекция объектов на видео\n",
        "- самостоятельно подготовить аналогичный ноутбук, но для распознавания объектов на видео\n",
        "- оформить отчет (в обоих случаях отчеты можно подготовить сразу в ноутбуке)\n",
        "ссылки в помощь:\n",
        "[первая](https://uproger.com/obuchaem-s-yolov8-na-polzovatelskih-dannyh-yolov8-instrukcziya-po-rabote/)"
      ],
      "metadata": {
        "id": "3Uf6LmDYb9nC"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}